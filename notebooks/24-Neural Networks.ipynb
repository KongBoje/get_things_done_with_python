{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson Analytics\n",
    "\n",
    "Watson Analytics is a Cloud Service offering AI capabilities via REST APIs. https://www.ibm.com/analytics/watson-analytics/us-en/index.html\n",
    "\n",
    "\n",
    "https://github.com/watson-developer-cloud/python-sdk\n",
    "\n",
    "```bash\n",
    "pip install watson-developer-cloud\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Getting the Service Credentials\n",
    "\n",
    "Service credentials are required to access the APIs.\n",
    "\n",
    "To run locally or outside of Bluemix you need the `username` and `password` credentials for each service. (Service credentials are different from your Bluemix account email and password.)\n",
    "\n",
    "To create an instance of the service:\n",
    "\n",
    "  * Log in to [Bluemix](https://console.ng.bluemix.net).\n",
    "  * Create an instance of the service:\n",
    "    1. In the Bluemix Catalog, select the Watson service you want to use. For our example, select under *Watson* the *Visual Recognition* service.\n",
    "    2. Type a unique name for the service instance in the Service name field. For example, type my-service-name. Leave the default values for the other options.\n",
    "    3. Click Create.\n",
    "    \n",
    "    \n",
    "To get your service credentials:\n",
    "\n",
    "  * Copy your credentials from the *Service Details* page. To find the the *Service Details* page for an existing service, navigate to your Bluemix dashboard and click the service name.\n",
    "  * On the *Service Details* page, click *Service Credentials*, and then *View Credentials*.\n",
    "Copy username and password.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"IBM_WATSON_API_KEY='YOUR_API_KEY'\" >> ./api_keys.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import api_keys\n",
    "\n",
    "API_KEY = {\n",
    "  \"url\": \"https://gateway-a.watsonplatform.net/visual-recognition/api\",\n",
    "  \"note\": \"It may take up to 5 minutes for this key to become active\",\n",
    "  \"api_key\": api_keys.IBM_WATSON_API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Network with Pre-trained Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See example:\n",
    "# https://github.com/watson-developer-cloud/python-sdk/blob/master/examples/visual_recognition_v3.py\n",
    "\n",
    "import json\n",
    "from watson_developer_cloud import VisualRecognitionV3\n",
    "\n",
    "\n",
    "test_url = 'https://www.ibm.com/ibm/ginni/images/ginni_bio_780x981_v4_03162016.jpg'\n",
    "\n",
    "visual_recognition = VisualRecognitionV3('2016-05-20', api_key=API_KEY['api_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what the Watson's Visual Recognition Classifier says to IBM's CEO Ginni Rometty.\n",
    "![](https://www.ibm.com/ibm/ginni/images/ginni_bio_780x981_v4_03162016.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images_processed\": 1,\n",
      "  \"custom_classes\": 0,\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"resolved_url\": \"https://www.ibm.com/ibm/ginni/images/ginni_bio_780x981_v4_03162016.jpg\",\n",
      "      \"source_url\": \"https://www.ibm.com/ibm/ginni/images/ginni_bio_780x981_v4_03162016.jpg\",\n",
      "      \"classifiers\": [\n",
      "        {\n",
      "          \"name\": \"default\",\n",
      "          \"classes\": [\n",
      "            {\n",
      "              \"class\": \"girl\",\n",
      "              \"type_hierarchy\": \"/person/female/woman/girl\",\n",
      "              \"score\": 0.643\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"woman\",\n",
      "              \"score\": 0.563\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"female\",\n",
      "              \"score\": 0.567\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"person\",\n",
      "              \"score\": 0.682\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"womans portrait photo\",\n",
      "              \"type_hierarchy\": \"/fabric/womans portrait photo\",\n",
      "              \"score\": 0.549\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"fabric\",\n",
      "              \"score\": 0.549\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"people\",\n",
      "              \"type_hierarchy\": \"/person/people\",\n",
      "              \"score\": 0.541\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"steward\",\n",
      "              \"type_hierarchy\": \"/person/steward\",\n",
      "              \"score\": 0.53\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"coal black color\",\n",
      "              \"score\": 0.711\n",
      "            }\n",
      "          ],\n",
      "          \"classifier_id\": \"default\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(visual_recognition.classify(images_url=test_url), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images_processed\": 1,\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"resolved_url\": \"https://www.ibm.com/ibm/ginni/images/ginni_bio_780x981_v4_03162016.jpg\",\n",
      "      \"source_url\": \"https://www.ibm.com/ibm/ginni/images/ginni_bio_780x981_v4_03162016.jpg\",\n",
      "      \"faces\": [\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 35,\n",
      "            \"max\": 44,\n",
      "            \"score\": 0.403753\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.989013,\n",
      "            \"gender\": \"FEMALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 337,\n",
      "            \"width\": 309,\n",
      "            \"top\": 168,\n",
      "            \"left\": 277\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(visual_recognition.detect_faces(images_url=test_url), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"classifiers\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(visual_recognition.list_classifiers(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read more about what is possible via the Python API, see https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/?python.\n",
    "\n",
    "In essence, the Python API is just wrapping HTTP REST API calls with the `requests` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to classify a local image?\n",
    "\n",
    "There are many labeled datasets used in image recognition research. One of them is the Caltech 101 dataset, see http://www.vision.caltech.edu/Image_Datasets/Caltech101/. The actual dataset is here: http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n",
    "\n",
    "\n",
    "After downloading and and uncompressing the dataset, we can send the image of a butterfly to Watson.\n",
    "![](image_0027.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images_processed\": 1,\n",
      "  \"custom_classes\": 0,\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"image\": \"./image_0027.jpg\",\n",
      "      \"classifiers\": [\n",
      "        {\n",
      "          \"name\": \"default\",\n",
      "          \"classes\": [\n",
      "            {\n",
      "              \"class\": \"monarch butterfly\",\n",
      "              \"type_hierarchy\": \"/animal/invertebrate/insect/monarch butterfly\",\n",
      "              \"score\": 0.954\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"butterfly\",\n",
      "              \"score\": 0.991\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"insect\",\n",
      "              \"score\": 0.991\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"invertebrate\",\n",
      "              \"score\": 0.991\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"animal\",\n",
      "              \"score\": 0.991\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"viceroy butterfly\",\n",
      "              \"type_hierarchy\": \"/animal/invertebrate/insect/viceroy butterfly\",\n",
      "              \"score\": 0.605\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"reddish orange color\",\n",
      "              \"score\": 0.984\n",
      "            }\n",
      "          ],\n",
      "          \"classifier_id\": \"default\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('./image_0027.jpg', 'rb') as image_file:\n",
    "    print(json.dumps(visual_recognition.classify(images_file=image_file, threshold=0.1), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "![](http://www.xpautographs.com/11337-7718-thickbox/mister-t-autograph.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images_processed\": 1,\n",
      "  \"custom_classes\": 0,\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"resolved_url\": \"http://www.xpautographs.com/11337-7718-thickbox/mister-t-autograph.jpg\",\n",
      "      \"source_url\": \"http://www.xpautographs.com/11337-7718-thickbox/mister-t-autograph.jpg\",\n",
      "      \"classifiers\": [\n",
      "        {\n",
      "          \"name\": \"default\",\n",
      "          \"classes\": [\n",
      "            {\n",
      "              \"class\": \"people\",\n",
      "              \"type_hierarchy\": \"/person/people\",\n",
      "              \"score\": 0.53\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"person\",\n",
      "              \"score\": 0.717\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"Indian red color\",\n",
      "              \"score\": 0.965\n",
      "            }\n",
      "          ],\n",
      "          \"classifier_id\": \"default\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "mister_t_url = 'http://www.xpautographs.com/11337-7718-thickbox/mister-t-autograph.jpg'\n",
    "print(json.dumps(visual_recognition.classify(images_url=mister_t_url), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.cphbusiness.dk/media/75910/lam.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images_processed\": 1,\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"resolved_url\": \"https://www.cphbusiness.dk/media/75910/lam.png\",\n",
      "      \"source_url\": \"https://www.cphbusiness.dk/media/75910/lam.png\",\n",
      "      \"faces\": [\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 65,\n",
      "            \"score\": 0.596227\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.993307,\n",
      "            \"gender\": \"MALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 272,\n",
      "            \"width\": 235,\n",
      "            \"top\": 92,\n",
      "            \"left\": 44\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "lars_url = 'https://www.cphbusiness.dk/media/75910/lam.png'\n",
    "print(json.dumps(visual_recognition.classify(images_url=lars_url), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.cphbusiness.dk/media/74691/ltje.jpg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images_processed\": 1,\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"resolved_url\": \"https://www.cphbusiness.dk/media/74691/ltje.jpg\",\n",
      "      \"source_url\": \"https://www.cphbusiness.dk/media/74691/ltje.jpg\",\n",
      "      \"faces\": [\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 35,\n",
      "            \"max\": 44,\n",
      "            \"score\": 0.506266\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.989013,\n",
      "            \"gender\": \"FEMALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 1158,\n",
      "            \"width\": 943,\n",
      "            \"top\": 470,\n",
      "            \"left\": 374\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "line_url = 'https://www.cphbusiness.dk/media/74691/ltje.jpg'\n",
    "print(json.dumps(visual_recognition.detect_faces(images_url=line_url), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Many Faces in an Image\n",
    "\n",
    "![](http://www.albanyjobfair.com/wp-content/uploads/2014/01/BIz-people-2-300x276.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images_processed\": 1,\n",
      "  \"custom_classes\": 0,\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"resolved_url\": \"http://www.albanyjobfair.com/wp-content/uploads/2014/01/BIz-people-2-300x276.jpg\",\n",
      "      \"source_url\": \"http://www.albanyjobfair.com/wp-content/uploads/2014/01/BIz-people-2-300x276.jpg\",\n",
      "      \"classifiers\": [\n",
      "        {\n",
      "          \"name\": \"default\",\n",
      "          \"classes\": [\n",
      "            {\n",
      "              \"class\": \"family\",\n",
      "              \"type_hierarchy\": \"/person/family\",\n",
      "              \"score\": 0.625\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"person\",\n",
      "              \"score\": 0.671\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"group of people\",\n",
      "              \"score\": 0.532\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"toga cloak\",\n",
      "              \"type_hierarchy\": \"/overgarment/toga cloak\",\n",
      "              \"score\": 0.531\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"cloak\",\n",
      "              \"score\": 0.531\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"overgarment\",\n",
      "              \"score\": 0.531\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"garment\",\n",
      "              \"score\": 0.531\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"people\",\n",
      "              \"type_hierarchy\": \"/person/people\",\n",
      "              \"score\": 0.53\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"alizarine red color\",\n",
      "              \"score\": 0.828\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"ivory color\",\n",
      "              \"score\": 0.735\n",
      "            }\n",
      "          ],\n",
      "          \"classifier_id\": \"default\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"images_processed\": 1,\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"resolved_url\": \"http://www.albanyjobfair.com/wp-content/uploads/2014/01/BIz-people-2-300x276.jpg\",\n",
      "      \"source_url\": \"http://www.albanyjobfair.com/wp-content/uploads/2014/01/BIz-people-2-300x276.jpg\",\n",
      "      \"faces\": [\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 35,\n",
      "            \"max\": 44,\n",
      "            \"score\": 0.506266\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.997527,\n",
      "            \"gender\": \"MALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 56,\n",
      "            \"width\": 51,\n",
      "            \"top\": 95,\n",
      "            \"left\": 172\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 35,\n",
      "            \"max\": 44,\n",
      "            \"score\": 0.390671\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.993307,\n",
      "            \"gender\": \"MALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 61,\n",
      "            \"width\": 61,\n",
      "            \"top\": 70,\n",
      "            \"left\": 233\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 18,\n",
      "            \"max\": 24,\n",
      "            \"score\": 0.656406\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.993307,\n",
      "            \"gender\": \"FEMALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 52,\n",
      "            \"width\": 43,\n",
      "            \"top\": 93,\n",
      "            \"left\": 32\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 18,\n",
      "            \"max\": 24,\n",
      "            \"score\": 0.502411\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.993307,\n",
      "            \"gender\": \"MALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 49,\n",
      "            \"width\": 43,\n",
      "            \"top\": 51,\n",
      "            \"left\": 148\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 18,\n",
      "            \"max\": 24,\n",
      "            \"score\": 0.502411\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.817574,\n",
      "            \"gender\": \"FEMALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 57,\n",
      "            \"width\": 42,\n",
      "            \"top\": 135,\n",
      "            \"left\": 107\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 18,\n",
      "            \"max\": 24,\n",
      "            \"score\": 0.503802\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.952574,\n",
      "            \"gender\": \"FEMALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 60,\n",
      "            \"width\": 52,\n",
      "            \"top\": 140,\n",
      "            \"left\": 227\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 18,\n",
      "            \"max\": 24,\n",
      "            \"score\": 0.502411\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.993307,\n",
      "            \"gender\": \"MALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 44,\n",
      "            \"width\": 44,\n",
      "            \"top\": 50,\n",
      "            \"left\": 47\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 18,\n",
      "            \"max\": 24,\n",
      "            \"score\": 0.270902\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.989013,\n",
      "            \"gender\": \"FEMALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 59,\n",
      "            \"width\": 46,\n",
      "            \"top\": 145,\n",
      "            \"left\": 55\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"age\": {\n",
      "            \"min\": 18,\n",
      "            \"max\": 24,\n",
      "            \"score\": 0.502411\n",
      "          },\n",
      "          \"gender\": {\n",
      "            \"score\": 0.989013,\n",
      "            \"gender\": \"FEMALE\"\n",
      "          },\n",
      "          \"face_location\": {\n",
      "            \"height\": 68,\n",
      "            \"width\": 49,\n",
      "            \"top\": 131,\n",
      "            \"left\": 188\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "group_url = 'http://www.albanyjobfair.com/wp-content/uploads/2014/01/BIz-people-2-300x276.jpg'\n",
    "\n",
    "print(json.dumps(visual_recognition.classify(images_url=group_url), indent=2))\n",
    "print(json.dumps(visual_recognition.detect_faces(images_url=group_url), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training your own Classifier\n",
    "\n",
    "This is your task now. Take some images from different categories from the Caltech 101 dataset and train the neural network with them. For example, as in the following:\n",
    "\n",
    "```python\n",
    "with open('/path/to/butterflies.zip', 'rb') as butterflies, \\\n",
    "     open('/path/to/airplanes.zip'), 'rb') as airplanes:\n",
    "    print(json.dumps(visual_recognition.create_classifier('ButterfliesvsPlanes', \n",
    "                                                          butterflies_positive_examples=butterflies, \n",
    "                                                          negative_examples=airplanes), \n",
    "                     indent=2))\n",
    "```\n",
    "\n",
    "When you created some classifiers, you can list them as in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"classifiers\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(visual_recognition.list_classifiers(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does this work? Introduction to Neural Networks.\n",
    "\n",
    "\n",
    "A next step from a single perceptron -as seen in the last lecture- to an image classifier as above is a Multi-layer Perceptron.\n",
    "\n",
    "![](http://www.saedsayad.com/images/Perceptron_bkp_1.png)\n",
    "\n",
    "\n",
    "\n",
    "The code in the following is adapted from Chapter 18 \"Neural Networks\" in the Data Science from Scratch book. The code can be found at: https://github.com/joelgrus/data-science-from-scratch/blob/master/code-python3/neural_networks.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 65/20000 [00:00<00:30, 647.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:28<00:00, 700.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "random.seed(0)   # to get repeatable results\n",
    "input_size = 25  # each input is a vector of length 25\n",
    "\n",
    "num_hidden = 5   # we'll have 5 neurons in the hidden layer\n",
    "output_size = 10 # we need 10 outputs for each input\n",
    "\n",
    "# each hidden neuron has one weight per input, plus a bias weight\n",
    "hidden_layer = [[random.random() for _ in range(input_size + 1)]\n",
    "                 for _ in range(num_hidden)]\n",
    "\n",
    "# each output neuron has one weight per hidden neuron, plus a bias weight\n",
    "output_layer = [[random.random() for _ in range(num_hidden + 1)]\n",
    "                 for _ in range(output_size)]\n",
    "\n",
    "# the network starts out with random weights\n",
    "network = [hidden_layer, output_layer]\n",
    "\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "# 10,000 iterations seems enough to converge\n",
    "for _ in tqdm(range(20000)):\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropagate(network, input_vector, target_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Trainings Dataset\n",
    "\n",
    "We want to create a Multi-layer Perceptron, which can classifiy -or recognize- the digits from zero to nine for us. In `raw_digits` we create digits consisting out of 5x5 binary pixels. Consequently, each input in our trainings dataset is a binary vector of length 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_digits = [\n",
    "        \"\"\"11111\n",
    "           1...1\n",
    "           1...1\n",
    "           1...1\n",
    "           11111\"\"\",\n",
    "        \"\"\"..1..\n",
    "           ..1..\n",
    "           ..1..\n",
    "           ..1..\n",
    "           ..1..\"\"\",\n",
    "        \"\"\"11111\n",
    "           ....1\n",
    "           11111\n",
    "           1....\n",
    "           11111\"\"\",\n",
    "        \"\"\"11111\n",
    "           ....1\n",
    "           11111\n",
    "           ....1\n",
    "           11111\"\"\",\n",
    "        \"\"\"1...1\n",
    "           1...1\n",
    "           11111\n",
    "           ....1\n",
    "           ....1\"\"\",\n",
    "        \"\"\"11111\n",
    "           1....\n",
    "           11111\n",
    "           ....1\n",
    "           11111\"\"\",\n",
    "        \"\"\"11111\n",
    "           1....\n",
    "           11111\n",
    "           1...1\n",
    "           11111\"\"\",\n",
    "        \"\"\"11111\n",
    "           ....1\n",
    "           ....1\n",
    "           ....1\n",
    "           ....1\"\"\",\n",
    "        \"\"\"11111\n",
    "           1...1\n",
    "           11111\n",
    "           1...1\n",
    "           11111\"\"\",\n",
    "        \"\"\"11111\n",
    "           1...1\n",
    "           11111\n",
    "           ....1\n",
    "           11111\"\"\"]\n",
    "\n",
    "\n",
    "def make_digit(raw_digit):\n",
    "    return [1 if c == '1' else 0\n",
    "            for row in raw_digit.split(\"\\n\")\n",
    "            for c in row.strip()]\n",
    "\n",
    "\n",
    "inputs = [make_digit(raw_digit) for raw_digit in raw_digits]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convience and reusabilty, we save the vectors containing the raw digits to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      " [1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1]\n",
      " [1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1]\n",
      " [1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "print(np.array(inputs, dtype=np.int8))\n",
    "#np.savetxt?\n",
    "np.savetxt('./simple_digit_trainingset.csv', np.array(inputs, dtype=np.int8), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,1,1,1,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,1,1,1,1,1\n",
      "0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0\n",
      "1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1\n",
      "1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1\n",
      "1,0,0,0,1,1,0,0,0,1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1\n",
      "1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1\n",
      "1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1\n",
      "1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1\n",
      "1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1\n",
      "1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat simple_digit_trainingset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create to helper functions, one for reading our trainings dataset from a file and a second one, which will plot it for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAycAAAGoCAYAAABc0JqNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f66479e9e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import csv\n",
    "import webget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "filename = './simple_digit_trainingset.csv'\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            label = reader.line_num - 1\n",
    "            image = np.array(row[:], dtype=np.int8)\n",
    "            data.append((label, image))\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_plot(data):\n",
    "    count = 0\n",
    "    f = plt.figure(figsize=(10, 5))\n",
    "    for idx, row in enumerate(data):\n",
    "        imarray = row[1].reshape((5, 5))\n",
    "        plt.subplot(2, 5, idx + 1)\n",
    "        plt.subplots_adjust(hspace=0.5)\n",
    "        count += 1\n",
    "        plt.title('Label = {}'.format(row[0]))\n",
    "        plt.imshow(imarray, cmap='Greys', interpolation='None')\n",
    "    return plt\n",
    "\n",
    "\n",
    "trainings_set = read_data(filename)\n",
    "plt.show(generate_plot(trainings_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Actual Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def dot(v, w):\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(dot(weights, inputs))\n",
    "\n",
    "\n",
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network (represented as a list of lists of lists of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "\n",
    "        input_with_bias = input_vector + [1]             # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias) # compute the output\n",
    "                  for neuron in layer]                   # for this layer\n",
    "        outputs.append(output)                           # and remember it\n",
    "\n",
    "        # the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def backpropagate(network, input_vector, target):\n",
    "\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "\n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target[i])\n",
    "                     for i, output in enumerate(outputs)]\n",
    "\n",
    "    # adjust weights for output layer (network[-1])\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            # print(i,j)\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "    #print('----')\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                      dot(output_deltas, [n[i] for n in network[-1]])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # adjust weights for hidden layer (network[0])\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, in_put in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * in_put\n",
    "\n",
    "\n",
    "def predict(in_put):\n",
    "    return feed_forward(network, in_put)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Test-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0], [0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0], [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], [0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAADCCAYAAADOxbSNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6637276ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_testset(data):\n",
    "    count = 0\n",
    "    f = plt.figure(figsize=(10, 5))\n",
    "    data = np.array(data)\n",
    "    for idx, row in enumerate(data):\n",
    "        imarray = row.reshape((5, 5))\n",
    "        plt.subplot(2, len(data), idx + 1)\n",
    "        plt.subplots_adjust(hspace=0.5)\n",
    "        count += 1\n",
    "        plt.imshow(imarray, cmap='Greys', interpolation='None')\n",
    "    return plt\n",
    "\n",
    "\n",
    "test_set = [[0,1,1,1,0,\n",
    "             0,0,0,1,1,\n",
    "             0,0,1,1,0,\n",
    "             0,0,0,1,1,\n",
    "             0,1,1,1,0],\n",
    "            [0,1,1,1,0,\n",
    "             1,0,0,1,1,\n",
    "             0,1,1,1,0,\n",
    "             1,0,0,1,1,\n",
    "             0,1,1,1,0],\n",
    "            [0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0],\n",
    "            [0,1,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0,\n",
    "             0,0,1,0,0]]\n",
    "print(test_set)\n",
    "plt.show(plot_testset(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [ 0.    0.    0.    0.98  0.    0.    0.    0.01  0.    0.05]\n",
      "9 [ 0.    0.    0.    0.    0.    0.65  0.    0.    0.96  1.  ]\n",
      "1 [ 0.    0.98  0.02  0.01  0.    0.    0.    0.    0.    0.  ]\n",
      "3 [ 0.    0.11  0.    0.86  0.    0.    0.    0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "for test_data in test_set:\n",
    "    result = predict(test_data)\n",
    "    result = np.array(result)\n",
    "    print(np.argmax(result), np.array_str(result, precision=2, suppress_small=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.96  0.    0.    0.    0.    0.    0.    0.02  0.03  0.  ]\n",
      "1 [ 0.    0.96  0.03  0.02  0.    0.    0.    0.    0.    0.  ]\n",
      "2 [ 0.    0.02  0.96  0.    0.    0.03  0.    0.    0.    0.  ]\n",
      "3 [ 0.    0.03  0.    0.97  0.    0.    0.    0.02  0.    0.03]\n",
      "4 [ 0.    0.02  0.01  0.    0.98  0.    0.    0.    0.    0.  ]\n",
      "5 [ 0.    0.    0.02  0.    0.    0.96  0.01  0.    0.02  0.01]\n",
      "6 [ 0.    0.    0.01  0.    0.01  0.01  0.99  0.    0.    0.  ]\n",
      "7 [ 0.02  0.    0.    0.02  0.    0.    0.    0.97  0.    0.  ]\n",
      "8 [ 0.04  0.    0.    0.    0.    0.02  0.    0.    0.96  0.03]\n",
      "9 [ 0.    0.    0.    0.01  0.    0.02  0.    0.    0.03  0.95]\n"
     ]
    }
   ],
   "source": [
    "for test_data in inputs:\n",
    "    result = predict(test_data)\n",
    "    result = np.array(result)\n",
    "    print(np.argmax(result), np.array_str(result, precision=2, suppress_small=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Done Properly...\n",
    "\n",
    "And we still have a bit to go from classifying digits with a Multi-layer Perceptron to a Convolutional Neural Network (CNN), which is the technique that IBM applies in Watson for visual recognition. A modern framework for implementing various types of neural networks is Google's Tensorflow.\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "You can get more information about it here:\n",
    "\n",
    "  * https://www.youtube.com/watch?v=qyvlt7kiQoI\n",
    "  * https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0\n",
    "  * https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py\n",
    "  * https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise!!!\n",
    "\n",
    "Your task is to extend the above example to work with the 'classical' MNIST dataset, which contains many thousands of handwritten digits. Your task is to watch the video https://www.youtube.com/watch?v=qyvlt7kiQoI on YouTube, which gives an introduction to Google's Tensorflow -a Python framework helping to build neural networks- and you follow the tutorial on https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist.\n",
    "\n",
    "You have to reproduce their solution and the results at least until step 6 (including step 6) and futher if you feel like it.\n",
    "\n",
    "\n",
    "## Hand-in Guidelines\n",
    "How is your hand-in expected to look like?\n",
    "\n",
    "  * You push the source code computing your solutions to a repository on Github.\n",
    "  * You create a README.md file that presents your solution, each result per questions, and it explains how to run your code to reproduce your results.\n",
    "  * Inform Helge when you are done. At latest at 24:00 the April 25th.\n",
    "  * You prepare a short (max. 10 minutes) presentation for the next session, so that the other students know what you have done and how you tackled the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Possible Projects:\n",
    "\n",
    "  * Implementation of a Salient Region Detector: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.228.5552&rep=rep1&type=pdf\n",
    "  * Audio Fingerprinting: http://willdrevo.com/fingerprinting-and-audio-recognition-with-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
